#!/usr/bin/env python
from __future__ import absolute_import
from collections import defaultdict

import argparse
import glob
import logging
import os
import sys
import re

# required to load all vcs modules
from pip.vcs import git, mercurial, subversion, bazaar  # noqa
from piptools.datastructures import Spec, SpecSet, ConflictError
from piptools.logging import logger
from piptools.package_manager import PackageManager
from piptools.resolver import Resolver


DEFAULT_REQUIREMENTS_FILE = 'requirements.in'
GLOB_PATTERN = '*requirements.in'


# Track external PyPi repos referenced
extra_index_urls = []


def setup_logging(verbose):
    if verbose:
        level = logging.DEBUG
    else:
        level = logging.INFO

    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(message)s', None)
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(level)

    from pip.log import logger as pip_logger
    pip_logger.consumers.append((pip_logger.VERBOSE_DEBUG, lambda msg: logger.debug('PIP said: ' + msg)))

def parse_args():
    parser = argparse.ArgumentParser(
            description='Compiles requirements.txt from requirements.in specs.')
    parser.add_argument('--extra-index-url', action='store', default=None,
            help="Add additional PyPi repo to search")
    parser.add_argument('--dry-run', action='store_true', default=False,
            help="Only show what would happen, don't change anything")
    parser.add_argument('--include-sources', '-i', action='store_true', default=False,
            help="Write comments to the output file, indicating how the compiled dependencies where calculated")
    parser.add_argument('--verbose', '-v', action='store_true', default=False,
            help='Show more output')
    parser.add_argument('--allow-unverified', nargs='*', action='store', default=[],
            help='Allow resolving this package from an unverified source (can be specified multiple times)')
    parser.add_argument('files', nargs='*')
    return parser.parse_args()


def walk_specfile(filename):
    """Walks over the given file, and returns (req, filename, lineno)
    tuples for each entry.
    """
    with open(filename, 'r') as f:
        reqs = f.read()

    for lineno, line in enumerate(reqs.splitlines(), 1):
        line = line.strip()
        if not line or line.startswith('#'):
            continue

        if line.startswith('-r'):
            requirement = line.split(None, 1)[1]
            # requirement file is relative to processed one
            requirement = os.path.join(os.path.dirname(filename), requirement)

            for spec in walk_specfile(requirement):
                yield spec.add_source('{0}:{1} -> {2}'.format(filename, lineno, spec.source))

        elif line.startswith('--extra-index-url'):
            repo = re.split('=| ', line)
            if len(repo) > 1:
                repo = repo[1]
                logger.debug('Found a link to additional PyPi repo -> {0}'.format(repo))
                if repo not in extra_index_urls:
                    extra_index_urls.append(repo)

        else:
            spec = Spec.from_line(line, source='{0}:{1}'.format(filename, lineno))
            yield spec


def collect_source_specs(filenames):
    """This function collects all of the (primary) source specs into
    a flattened list of specs.
    """
    for filename in filenames:
        for spec in walk_specfile(filename):
            yield spec


def compile_specs(source_files, include_sources=False, dry_run=False, allow_unverified=None):
    logger.debug('===> Collecting source requirements')
    top_level_specs = list(collect_source_specs(source_files))

    spec_set = SpecSet()
    spec_set.add_specs(top_level_specs)
    logger.debug('%s' % (spec_set,))

    logger.debug('')
    logger.debug('===> Normalizing source requirements')
    spec_set = spec_set.normalize()
    logger.debug('%s' % (spec_set,))

    package_manager = PackageManager(extra_index_urls, allow_unverified=allow_unverified)

    logger.debug('')
    logger.debug('===> Resolving full tree')

    resolver = Resolver(spec_set, package_manager=package_manager)
    try:
        pinned_spec_set = resolver.resolve()
    except ConflictError as e:
        logger.error("error: {0}".format(e))
        sys.exit(1)

    logger.debug('')
    logger.debug('===> Pinned spec set resolved')
    for spec in pinned_spec_set:
        logger.debug('- %s' % (spec,))

    if dry_run:
        return

    logger.debug('')
    logger.debug('===> Writing compiled files')

    # The spec set is global for all files passed to pip-compile. Here we go
    # through the resolver again (which will use its cache from the initial
    # run) to determine where to write each dependency.
    split = defaultdict(SpecSet)
    for spec in top_level_specs:
        split[spec.source.split(':')[0]].add_spec(spec)

    for source_file, spec_set in split.iteritems():
        resolver = Resolver(spec_set, package_manager=package_manager)
        with logger.silent():
            local_pinned = resolver.resolve()
        name, ext = os.path.splitext(source_file)
        compiled_file = '{0}.txt'.format(name)
        assert source_file != compiled_file, "Can't overwrite %s" % source_file
        logger.debug('{0} -> {1}'.format(source_file, compiled_file))
        with open(compiled_file, 'w') as f:
            for spec in sorted(local_pinned, key=unicode):
                f.write(unicode(spec).encode('utf-8'))
                if include_sources:
                    f.write('  # {}'.format(spec.source))
                f.write('\n')

            # Include external PyPi sources
            if len(extra_index_urls):
                for extra_index_url in extra_index_urls:
                    f.write("--extra-index-url {0}\n".format(extra_index_url))


def main():
    args = parse_args()
    setup_logging(args.verbose)

    if args.extra_index_url:
        urls = args.extra_index_url.split(',')
        extra_index_urls.extend(urls)

    src_files = args.files or glob.glob(GLOB_PATTERN)
    compile_specs(src_files, include_sources=args.include_sources, dry_run=args.dry_run, allow_unverified=args.allow_unverified)

    if args.dry_run:
        logger.info("Dry-run, so nothing updated.")
    else:
        logger.info("Dependencies updated.")


if __name__ == '__main__':
    main()
